{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf15302",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/HZhalex/F5-TTS-Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6215080a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"ckpts/F5-TTS-Vietnamese\", exist_ok=True)\n",
    "!wget -O ckpts/F5-TTS-Vietnamese/model_500000.pt https://huggingface.co/hynt/F5-TTS-Vietnamese-ViVoice/resolve/main/model_last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896913e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torchcodec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a2731",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd F5-TTS-Vietnamese\n",
    "\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81467ea8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple F5-TTS Inference Script\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "\n",
    "from f5_tts.model import DiT, CFM\n",
    "from f5_tts.model.utils import get_tokenizer, convert_char_to_pinyin\n",
    "\n",
    "# ==================== CẤU HÌNH ====================\n",
    "\n",
    "MODEL_PATH = \"/content/ckpts/F5-TTS-Vietnamese/model_500000.pt\"\n",
    "VOCAB_PATH = \"/content/ckpts/F5-TTS-Vietnamese/vocab.txt\"\n",
    "\n",
    "REF_AUDIO_PATH = \"/content/Bình (nam miền Bắc).wav\"\n",
    "REF_TEXT = \"Anh chỉ muốn được nhìn nhận như là một huấn luyện viên.\"\n",
    "\n",
    "GEN_TEXT = \"Xin chào, đây là văn bản tôi muốn chuyển thành giọng nói\"\n",
    "\n",
    "OUTPUT_PATH = \"output_generated.wav\"\n",
    "\n",
    "MODEL_CONFIG = {\n",
    "    \"dim\": 1024,\n",
    "    \"depth\": 22,\n",
    "    \"heads\": 16,\n",
    "    \"ff_mult\": 2,\n",
    "    \"text_dim\": 512,\n",
    "    \"text_mask_padding\": False,\n",
    "    \"conv_layers\": 4,\n",
    "    \"pe_attn_head\": 1,\n",
    "}\n",
    "\n",
    "MEL_SPEC_CONFIG = {\n",
    "    \"n_fft\": 1024,\n",
    "    \"hop_length\": 256,\n",
    "    \"win_length\": 1024,\n",
    "    \"n_mel_channels\": 100,\n",
    "    \"target_sample_rate\": 24000,\n",
    "    \"mel_spec_type\": \"vocos\",\n",
    "}\n",
    "\n",
    "NFE_STEP = 32\n",
    "CFG_STRENGTH = 2.0\n",
    "SWAY_SAMPLING_COEF = -1.0\n",
    "SPEED = 1.0\n",
    "TARGET_RMS = 0.1\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ==================== FUNCTIONS ====================\n",
    "\n",
    "def load_vocoder(device=DEVICE):\n",
    "    from vocos import Vocos\n",
    "    print(\"Đang tải Vocos vocoder...\")\n",
    "    vocoder = Vocos.from_pretrained(\"charactr/vocos-mel-24khz\").to(device)\n",
    "    return vocoder\n",
    "\n",
    "\n",
    "def load_f5tts_model(model_path, vocab_path, model_config, mel_spec_config, device):\n",
    "    print(f\"Đang load vocab từ: {vocab_path}\")\n",
    "    vocab_char_map, vocab_size = get_tokenizer(vocab_path, tokenizer=\"custom\")\n",
    "    print(f\"Vocab size: {vocab_size}\")\n",
    "    \n",
    "    print(f\"Đang khởi tạo model DiT...\")\n",
    "    transformer = DiT(\n",
    "        **model_config,\n",
    "        text_num_embeds=vocab_size,\n",
    "        mel_dim=mel_spec_config[\"n_mel_channels\"]\n",
    "    )\n",
    "    \n",
    "    model = CFM(\n",
    "        transformer=transformer,\n",
    "        mel_spec_kwargs=mel_spec_config,\n",
    "        odeint_kwargs=dict(method=\"euler\"),\n",
    "        vocab_char_map=vocab_char_map,\n",
    "    ).to(device)\n",
    "    \n",
    "    print(f\"Đang load checkpoint từ: {model_path}\")\n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    if \"ema_model_state_dict\" in checkpoint:\n",
    "        state_dict = {\n",
    "            k.replace(\"ema_model.\", \"\"): v\n",
    "            for k, v in checkpoint[\"ema_model_state_dict\"].items()\n",
    "            if k not in [\"initted\", \"step\"]\n",
    "        }\n",
    "    elif \"model_state_dict\" in checkpoint:\n",
    "        state_dict = checkpoint[\"model_state_dict\"]\n",
    "    else:\n",
    "        state_dict = checkpoint\n",
    "    \n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"✓ Model đã được load thành công!\")\n",
    "    return model, vocab_char_map\n",
    "\n",
    "\n",
    "def preprocess_audio(audio_path, target_sample_rate=24000, target_rms=TARGET_RMS, device=DEVICE):\n",
    "    print(f\"Đang load audio từ: {audio_path}\")\n",
    "    audio, sr = torchaudio.load(audio_path)\n",
    "    \n",
    "    if audio.shape[0] > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "    \n",
    "    rms = torch.sqrt(torch.mean(torch.square(audio)))\n",
    "    if rms < target_rms:\n",
    "        audio = audio * target_rms / rms\n",
    "    \n",
    "    if sr != target_sample_rate:\n",
    "        resampler = torchaudio.transforms.Resample(sr, target_sample_rate)\n",
    "        audio = resampler(audio)\n",
    "    \n",
    "    audio = audio.to(device)\n",
    "    print(f\"✓ Audio shape: {audio.shape}, Sample rate: {target_sample_rate}\")\n",
    "    print(f\"✓ Original RMS: {rms.item():.4f}\")\n",
    "    \n",
    "    return audio, target_sample_rate, rms\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_speech(model, vocoder, ref_audio, ref_text, gen_text, vocab_char_map, ref_audio_rms):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"BẮT ĐẦU GENERATE SPEECH\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    print(f\"\\nReference text: {ref_text}\")\n",
    "    print(f\"Generate text: {gen_text}\")\n",
    "    \n",
    "    text_list = [ref_text + \" \" + gen_text]\n",
    "    final_text_list = convert_char_to_pinyin(text_list)\n",
    "    print(f\"Processed text: {final_text_list}\")\n",
    "    \n",
    "    ref_audio_len = ref_audio.shape[-1] // MEL_SPEC_CONFIG[\"hop_length\"]\n",
    "    ref_text_len = len(ref_text.encode(\"utf-8\"))\n",
    "    gen_text_len = len(gen_text.encode(\"utf-8\"))\n",
    "    \n",
    "    duration = ref_audio_len + int(ref_audio_len / ref_text_len * gen_text_len / SPEED)\n",
    "    \n",
    "    print(f\"\\nRef audio length: {ref_audio_len} frames\")\n",
    "    print(f\"Target duration: {duration} frames\")\n",
    "    print(f\"Estimated audio length: {duration * MEL_SPEC_CONFIG['hop_length'] / MEL_SPEC_CONFIG['target_sample_rate']:.2f}s\")\n",
    "    \n",
    "    print(f\"\\nGenerating với {NFE_STEP} denoising steps...\")\n",
    "    generated, trajectory = model.sample(\n",
    "        cond=ref_audio,\n",
    "        text=final_text_list,\n",
    "        duration=duration,\n",
    "        steps=NFE_STEP,\n",
    "        cfg_strength=CFG_STRENGTH,\n",
    "        sway_sampling_coef=SWAY_SAMPLING_COEF,\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Generated mel shape: {generated.shape}\")\n",
    "    \n",
    "    generated = generated[:, ref_audio_len:, :]\n",
    "    \n",
    "    print(\"Đang chuyển mel spectrogram sang waveform...\")\n",
    "    gen_mel_spec = generated.permute(0, 2, 1)\n",
    "    generated_wave = vocoder.decode(gen_mel_spec).cpu()\n",
    "    \n",
    "    if ref_audio_rms < TARGET_RMS:\n",
    "        generated_wave = generated_wave * ref_audio_rms / TARGET_RMS\n",
    "    \n",
    "    print(f\"✓ Generated wave shape: {generated_wave.shape}\")\n",
    "    \n",
    "    return generated_wave, MEL_SPEC_CONFIG[\"target_sample_rate\"]\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"F5-TTS SIMPLE INFERENCE\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Device: {DEVICE}\\n\")\n",
    "    \n",
    "    for path, name in [\n",
    "        (MODEL_PATH, \"Model\"),\n",
    "        (VOCAB_PATH, \"Vocab\"),\n",
    "        (REF_AUDIO_PATH, \"Reference audio\")\n",
    "    ]:\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"{name} không tồn tại: {path}\")\n",
    "    \n",
    "    model, vocab_char_map = load_f5tts_model(\n",
    "        MODEL_PATH,\n",
    "        VOCAB_PATH,\n",
    "        MODEL_CONFIG,\n",
    "        MEL_SPEC_CONFIG,\n",
    "        DEVICE\n",
    "    )\n",
    "    \n",
    "    vocoder = load_vocoder(DEVICE)\n",
    "    \n",
    "    ref_audio, sr, ref_audio_rms = preprocess_audio(\n",
    "        REF_AUDIO_PATH,\n",
    "        MEL_SPEC_CONFIG[\"target_sample_rate\"],\n",
    "        TARGET_RMS,\n",
    "        DEVICE\n",
    "    )\n",
    "    \n",
    "    generated_wave, sample_rate = generate_speech(\n",
    "        model=model,\n",
    "        vocoder=vocoder,\n",
    "        ref_audio=ref_audio,\n",
    "        ref_text=REF_TEXT,\n",
    "        gen_text=GEN_TEXT,\n",
    "        vocab_char_map=vocab_char_map,\n",
    "        ref_audio_rms=ref_audio_rms\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nĐang lưu audio vào: {OUTPUT_PATH}\")\n",
    "    sf.write(\n",
    "        OUTPUT_PATH,\n",
    "        generated_wave.squeeze().numpy(),\n",
    "        sample_rate\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"✓ HOÀN THÀNH!\")\n",
    "    print(f\"✓ File audio đã được lưu tại: {OUTPUT_PATH}\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200c0da7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72e9c5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0192f280",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
