{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52df49b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/HZhalex/F5-TTS-Vietnamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaec77a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"ckpts/F5-TTS-Vietnamese\", exist_ok=True)\n",
    "!wget -O ckpts/F5-TTS-Vietnamese/model_500000.pt https://huggingface.co/hynt/F5-TTS-Vietnamese-ViVoice/resolve/main/model_last.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ca522",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install torchcodec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82006d56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%cd F5-TTS-Vietnamese\n",
    "\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bb20b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "from vocos import Vocos\n",
    "from f5_tts.model import DiT, CFM\n",
    "from f5_tts.model.utils import get_tokenizer, convert_char_to_pinyin\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import queue\n",
    "import time\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c9ef1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "MODEL_PATH = \"/content/ckpts/F5-TTS-Vietnamese/model_500000.pt\"\n",
    "VOCAB_PATH = \"/content/F5-TTS-Vietnamese/vocab.txt\"\n",
    "REF_AUDIO_DIR = \"/content/ref_audios\"\n",
    "REF_TEXT = \"Anh chỉ muốn được nhìn nhận như là một huấn luyện viên.\"\n",
    "BASE_DIR = \"/content/drive/MyDrive/task data audio/tinh_ban\"\n",
    "SPLITS = [\"train\", \"val\", \"test\"]\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d645b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# SINGLE-THREAD GENERATION (vì model không support parallel)\n",
    "INFERENCE_STEPS = 16  # Quality cao như bạn yêu cầu\n",
    "NUM_REF_AUDIOS = 104\n",
    "\n",
    "# ASYNC I/O để tận dụng tài nguyên\n",
    "NUM_SAVE_WORKERS = 16  # Save file song song\n",
    "SAVE_BUFFER_SIZE = 500  # Buffer lớn\n",
    "\n",
    "# Tối ưu PyTorch tối đa\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.set_float32_matmul_precision('high')\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cuda.matmul.allow_tf32 = True\n",
    "    torch.backends.cudnn.allow_tf32 = True\n",
    "    # Tắt gradient computation hoàn toàn\n",
    "    torch.set_grad_enabled(False)\n",
    "\n",
    "print(f\"   - FP16: {DEVICE == 'cuda'}\")\n",
    "print(f\"   - TF32: {DEVICE == 'cuda'}\")\n",
    "print(f\"   - Async save: {NUM_SAVE_WORKERS} workers\")\n",
    "print(f\"   - Inference steps: {INFERENCE_STEPS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0e755b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n Loading model\")\n",
    "vocab_char_map, vocab_size = get_tokenizer(VOCAB_PATH, tokenizer=\"custom\")\n",
    "model = CFM(\n",
    "    transformer=DiT(\n",
    "        dim=1024, depth=22, heads=16, ff_mult=2, text_dim=512, text_mask_padding=False,\n",
    "        text_num_embeds=vocab_size, mel_dim=100, conv_layers=4, pe_attn_head=1\n",
    "    ),\n",
    "    mel_spec_kwargs=dict(\n",
    "        n_fft=1024, hop_length=256, win_length=1024,\n",
    "        n_mel_channels=100, target_sample_rate=24000, mel_spec_type=\"vocos\"\n",
    "    ),\n",
    "    odeint_kwargs=dict(method=\"euler\"),\n",
    "    vocab_char_map=vocab_char_map,\n",
    ").to(DEVICE)\n",
    "\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=DEVICE, weights_only=False)\n",
    "if \"ema_model_state_dict\" in checkpoint:\n",
    "    state_dict = {k.replace(\"ema_model.\", \"\"): v for k, v in checkpoint[\"ema_model_state_dict\"].items()\n",
    "                  if k not in [\"initted\", \"step\"]}\n",
    "elif \"model_state_dict\" in checkpoint:\n",
    "    state_dict = checkpoint[\"model_state_dict\"]\n",
    "else:\n",
    "    state_dict = checkpoint\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "\n",
    "# FP16 conversion\n",
    "if DEVICE == \"cuda\":\n",
    "    model = model.half()\n",
    "    print(\" Model converted to FP16\")\n",
    "\n",
    "vocoder = Vocos.from_pretrained(\"charactr/vocos-mel-24khz\").to(DEVICE)\n",
    "if DEVICE == \"cuda\":\n",
    "    vocoder = vocoder.half()\n",
    "\n",
    "print(\" Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a79532",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n Loading reference audios\")\n",
    "ref_audios = {}\n",
    "ref_lens = {}\n",
    "\n",
    "for i in range(1, NUM_REF_AUDIOS + 1):\n",
    "    ref_path = os.path.join(REF_AUDIO_DIR, f\"id_{i}.wav\")\n",
    "    if not os.path.exists(ref_path):\n",
    "        continue\n",
    "\n",
    "    audio, sr = torchaudio.load(ref_path)\n",
    "    if audio.shape[0] > 1:\n",
    "        audio = torch.mean(audio, dim=0, keepdim=True)\n",
    "\n",
    "    rms = torch.sqrt(torch.mean(torch.square(audio)))\n",
    "    if rms < 0.1:\n",
    "        audio = audio * 0.1 / rms\n",
    "\n",
    "    if sr != 24000:\n",
    "        audio = torchaudio.transforms.Resample(sr, 24000)(audio)\n",
    "\n",
    "    ref_audios[i] = audio.to(DEVICE)\n",
    "    if DEVICE == \"cuda\":\n",
    "        ref_audios[i] = ref_audios[i].half()\n",
    "    ref_lens[i] = audio.shape[-1] // 256\n",
    "\n",
    "print(f\" Loaded {len(ref_audios)}/{NUM_REF_AUDIOS} reference audios\")\n",
    "\n",
    "missing_refs = [i for i in range(1, NUM_REF_AUDIOS + 1) if i not in ref_audios]\n",
    "if missing_refs:\n",
    "    print(f\"  Missing {len(missing_refs)} refs: {missing_refs[:5]}...\")\n",
    "else:\n",
    "    print(f\" All {NUM_REF_AUDIOS} reference audios present!\")\n",
    "\n",
    "ref_text_len = len(REF_TEXT.encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01c6487",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def generate_audio_optimized(ref_audio, ref_len, gen_text):\n",
    "    \"\"\"Highly optimized single generation\"\"\"\n",
    "    # Convert text (CPU bound)\n",
    "    text_list = [REF_TEXT + \" \" + gen_text]\n",
    "    final_text = convert_char_to_pinyin(text_list)\n",
    "\n",
    "    # Calculate duration\n",
    "    gen_text_len = len(gen_text.encode(\"utf-8\"))\n",
    "    duration = ref_len + int(ref_len / ref_text_len * gen_text_len)\n",
    "\n",
    "    # Generate (GPU bound)\n",
    "    generated, _ = model.sample(\n",
    "        cond=ref_audio,\n",
    "        text=final_text,\n",
    "        duration=duration,\n",
    "        steps=INFERENCE_STEPS,\n",
    "        cfg_strength=2.0,\n",
    "        sway_sampling_coef=-1.0\n",
    "    )\n",
    "\n",
    "    # Post-process\n",
    "    generated = generated[:, ref_len:, :]\n",
    "    gen_mel_spec = generated.permute(0, 2, 1)\n",
    "\n",
    "    # Decode with autocast\n",
    "    with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "        wave = vocoder.decode(gen_mel_spec)\n",
    "\n",
    "    return wave.squeeze().cpu().float().numpy()\n",
    "\n",
    "\n",
    "\n",
    "save_queue = queue.Queue(maxsize=SAVE_BUFFER_SIZE)\n",
    "save_stats = {'saved': 0, 'errors': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ddf813",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_worker():\n",
    "    while True:\n",
    "        item = save_queue.get()\n",
    "        if item is None:\n",
    "            break\n",
    "        path, wave = item\n",
    "        try:\n",
    "            sf.write(path, wave, 24000)\n",
    "            save_stats['saved'] += 1\n",
    "        except Exception as e:\n",
    "            save_stats['errors'] += 1\n",
    "        save_queue.task_done()\n",
    "\n",
    "save_executor = ThreadPoolExecutor(max_workers=NUM_SAVE_WORKERS)\n",
    "for _ in range(NUM_SAVE_WORKERS):\n",
    "    save_executor.submit(save_worker)\n",
    "\n",
    "print(f\"\\n Save workers started ({NUM_SAVE_WORKERS} threads)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aea56a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "total_start = time.time()\n",
    "total_generated_all = 0\n",
    "\n",
    "for split in SPLITS:\n",
    "    split_start = time.time()\n",
    "\n",
    "\n",
    "    labels_path = os.path.join(BASE_DIR, split, \"labels.txt\")\n",
    "    audio_dir = os.path.join(BASE_DIR, split, \"audio\")\n",
    "    os.makedirs(audio_dir, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(labels_path):\n",
    "        print(f\"{labels_path} not found, skipping...\")\n",
    "        continue\n",
    "\n",
    "    with open(labels_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        labels = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    total_samples = len(labels)\n",
    "    print(f\" Total samples: {total_samples:,}\")\n",
    "\n",
    "    samples_per_ref = total_samples // NUM_REF_AUDIOS\n",
    "    remainder = total_samples % NUM_REF_AUDIOS\n",
    "    print(f\" Distribution: ~{samples_per_ref} samples per ref audio\")\n",
    "    print(f\" Using all {len(ref_audios)} reference audios\\n\")\n",
    "\n",
    "    sample_idx = 0\n",
    "    generated_count = 0\n",
    "    skipped_count = 0\n",
    "    error_count = 0\n",
    "    refs_used = 0\n",
    "\n",
    "    pbar = tqdm(\n",
    "        total=total_samples,\n",
    "        desc=f\"  {split.upper()}\",\n",
    "        ncols=100,\n",
    "        bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'\n",
    "    )\n",
    "\n",
    "    # Speed tracking\n",
    "    speed_window = []\n",
    "    last_update = time.time()\n",
    "    last_count = 0\n",
    "\n",
    "    for ref_id in range(1, NUM_REF_AUDIOS + 1):\n",
    "        if ref_id not in ref_audios:\n",
    "            continue\n",
    "\n",
    "        refs_used += 1\n",
    "        num_samples = samples_per_ref + (1 if ref_id <= remainder else 0)\n",
    "\n",
    "        if sample_idx >= total_samples:\n",
    "            break\n",
    "\n",
    "        end_idx = min(sample_idx + num_samples, total_samples)\n",
    "        ref_labels = labels[sample_idx:end_idx]\n",
    "\n",
    "        for i, text in enumerate(ref_labels):\n",
    "            idx = sample_idx + i + 1\n",
    "            output_path = os.path.join(audio_dir, f\"{idx}.wav\")\n",
    "\n",
    "            # Skip existing\n",
    "            if os.path.exists(output_path):\n",
    "                skipped_count += 1\n",
    "                pbar.update(1)\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Generate audio\n",
    "                wave = generate_audio_optimized(\n",
    "                    ref_audios[ref_id],\n",
    "                    ref_lens[ref_id],\n",
    "                    text\n",
    "                )\n",
    "\n",
    "                # Queue for async save\n",
    "                save_queue.put((output_path, wave))\n",
    "                generated_count += 1\n",
    "\n",
    "                # Update progress\n",
    "                pbar.update(1)\n",
    "\n",
    "                # Calculate and display speed every 5 seconds\n",
    "                now = time.time()\n",
    "                if now - last_update >= 5.0:\n",
    "                    interval = now - last_update\n",
    "                    count_delta = generated_count - last_count\n",
    "                    instant_speed = count_delta / interval\n",
    "\n",
    "                    speed_window.append(instant_speed)\n",
    "                    if len(speed_window) > 12:  # Keep last 60 seconds\n",
    "                        speed_window.pop(0)\n",
    "\n",
    "                    avg_speed = sum(speed_window) / len(speed_window)\n",
    "\n",
    "                    pbar.set_postfix({\n",
    "                        'speed': f'{instant_speed:.1f}f/s',\n",
    "                        'avg': f'{avg_speed:.1f}f/s',\n",
    "                        'queue': save_queue.qsize()\n",
    "                    })\n",
    "\n",
    "                    last_update = now\n",
    "                    last_count = generated_count\n",
    "\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                if error_count <= 5:  # Only show first 5 errors\n",
    "                    pbar.write(f\" Error at sample {idx}: {str(e)[:70]}\")\n",
    "                pbar.update(1)\n",
    "\n",
    "        sample_idx = end_idx\n",
    "\n",
    "    # Wait for all saves to complete\n",
    "    save_queue.join()\n",
    "    pbar.close()\n",
    "\n",
    "    split_time = time.time() - split_start\n",
    "    speed = generated_count / split_time if split_time > 0 else 0\n",
    "    total_generated_all += generated_count\n",
    "\n",
    "    print(f\"\\n{'─'*70}\")\n",
    "    print(f\" {split.upper()} Completed:\")\n",
    "    print(f\"   Refs used:      {refs_used}/{NUM_REF_AUDIOS}\")\n",
    "    print(f\"   Generated:      {generated_count:,} files\")\n",
    "    print(f\"   Skipped:        {skipped_count:,} files\")\n",
    "    print(f\"   Errors:         {error_count:,} files\")\n",
    "    print(f\"   Time:           {split_time/60:.1f} minutes ({split_time:.0f}s)\")\n",
    "    print(f\"   Average speed:  {speed:.2f} files/sec\")\n",
    "\n",
    "    if speed > 0 and generated_count > 0:\n",
    "        # Project time for remaining data\n",
    "        remaining_splits = len(SPLITS) - SPLITS.index(split) - 1\n",
    "        if remaining_splits > 0:\n",
    "            estimated_remaining = (total_samples * remaining_splits) / speed / 60\n",
    "            print(f\"   Est. remaining: ~{estimated_remaining:.0f} minutes\")\n",
    "\n",
    "    print(f\"{'─'*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580843a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Shutdown save workers\n",
    "for _ in range(NUM_SAVE_WORKERS):\n",
    "    save_queue.put(None)\n",
    "save_executor.shutdown(wait=True)\n",
    "\n",
    "total_time = time.time() - total_start\n",
    "avg_speed = total_generated_all / total_time if total_time > 0 else 0\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\" ALL PROCESSING COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"   Total generated:  {total_generated_all:,} files\")\n",
    "print(f\"   Total time:       {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "print(f\"   Average speed:    {avg_speed:.2f} files/sec\")\n",
    "print(f\"   Files saved:      {save_stats['saved']:,}\")\n",
    "print(f\"   Save errors:      {save_stats['errors']:,}\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631d6eaa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89de90d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
